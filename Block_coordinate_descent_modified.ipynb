{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KDbRlCKv4U8",
        "outputId": "4b4b68df-1eaa-4a62-ea53-f65107f29a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 1.11.0+cu113\n",
            "Torchvision Version: 0.12.0+cu113\n",
            "GPU is available? True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "\n",
        "from utilities import *\n",
        "from block_coordinate_functions import *\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"Torchvision Version:\", torchvision.__version__)\n",
        "print(\"GPU is available?\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nYF1cnvPwthx"
      },
      "outputs": [],
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqvTMJAbw74Q"
      },
      "source": [
        "# Imported datasets\n",
        "For the testing and comparison of our algorithms we will use the following datasets:\n",
        "\n",
        "1. MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "icE91aqaw110"
      },
      "outputs": [],
      "source": [
        "ts = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0,), (1,))])\n",
        "mnist_trainset = datasets.MNIST('../data', train=True, download=True, transform=ts)\n",
        "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PEt-flsyEKM"
      },
      "source": [
        "# Train - test split\n",
        "\n",
        "Code taken from https://github.com/timlautk/BCD-for-DNNs-PyTorch/blob/master/bcd_dnn_mlp_mnist.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hVoD2jFeg-69"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test = train_test_split(mnist_trainset, mnist_testset)\n",
        "\n",
        "# we move to device to use GPU\n",
        "\n",
        "x_train = x_train.to(device = device)\n",
        "x_test = x_test.to(device = device)\n",
        "y_train = y_train.to(device = device)\n",
        "y_test = y_test.to(device = device)\n",
        "\n",
        "# we perform one-hot encoding on the y-> y_one_hot will be a tensor of dimension 10*training_samples, for each sample there\n",
        "# will be a one in the row corresponding to the class.\n",
        "\n",
        "N = y_train.shape[0]\n",
        "K = 10 # number of classes\n",
        "y_one_hot = torch.zeros(N, K).to(device = device).scatter_(1, torch.reshape(y_train,(N,1)), 1)\n",
        "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
        "\n",
        "N_test = y_test.shape[0]\n",
        "y_test_one_hot = torch.zeros(N_test, K).to(device = device).scatter_(1, torch.reshape(y_test,(N_test,1)), 1)\n",
        "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me_6E9_Hxsxw"
      },
      "source": [
        "# Architecture initialization\n",
        "\n",
        "For the MultiLayerPerceptron we have the parameters **input_size** , **hidden_size**,**output_size** corresponding to the size of the input layer, the hidden layer and the output layer, respectively.\n",
        "\n",
        "The MLP only has 3 layers like https://github.com/timlautk/BCD-for-DNNs-PyTorch/blob/master/bcd_dnn_mlp_mnist.ipynb as a starting point.\n",
        "\n",
        "Also we use ReLU currently for the same reason."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hlRg4UWiezMt"
      },
      "outputs": [],
      "source": [
        "input_size = 28*28\n",
        "hidden_size = 1500\n",
        "output_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0HQgkqHxr_zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e08665-964f-4cd6-ca38-27abe6cceed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 60000])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(32)\n",
        "d0 = input_size\n",
        "d1 = d2 = 1500\n",
        "d3 = output_size \n",
        "\n",
        "# The layers are: input + 2 hidden + output\n",
        "\n",
        "# we represent the weigths of each layer as matrices with d_{i-1} columns and d_{i} rows\n",
        "\n",
        "# Weight initialization (we replicate pytorch initialization)\n",
        "std_1 = math.sqrt(1/d0)\n",
        "W1 = torch.FloatTensor(d1, d0).uniform_(-std_1, std_1)\n",
        "b1 = torch.FloatTensor(d1, 1).uniform_(-std_1, std_1)\n",
        "\n",
        "# we move them to GPU\n",
        "b1 = b1.to('cuda:0')\n",
        "W1 = W1.to('cuda:0')\n",
        "\n",
        "\n",
        "std_2 = math.sqrt(1/d1)\n",
        "W2 = torch.FloatTensor(d2, d1).uniform_(-std_2, std_2)\n",
        "b2 = torch.FloatTensor(d2, 1).uniform_(-std_2, std_2)\n",
        "\n",
        "# we move them to GPU\n",
        "b2 = b2.to('cuda:0')\n",
        "W2 = W2.to('cuda:0')\n",
        "\n",
        "std_3 = math.sqrt(1/d2)\n",
        "W3 = torch.FloatTensor(d3, d2).uniform_(-std_3, std_3)\n",
        "b3 = torch.FloatTensor(d3, 1).uniform_(-std_3, std_3)\n",
        "\n",
        "# we move them to GPU\n",
        "b3 = b3.to('cuda:0')\n",
        "W3 = W3.to('cuda:0')\n",
        "\n",
        "\n",
        "U1 = torch.addmm(b1.repeat(1, N), W1, x_train) # equivalent to W1@x_train+b1.repeat(1,N)\n",
        "V1 = nn.ReLU()(U1)\n",
        "U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
        "V2 = nn.ReLU()(U2)\n",
        "U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
        "V3 = U3\n",
        "\n",
        "print(V3.shape)\n",
        "\n",
        "# constant initializations\n",
        "gamma = 1\n",
        "gamma1 = gamma2 = gamma3 = gamma4 = gamma\n",
        "\n",
        "rho = gamma\n",
        "rho1 = rho2 = rho3 = rho4 = rho\n",
        "\n",
        "\n",
        "alpha = 5\n",
        "alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 \\\n",
        "= alpha8 = alpha9 = alpha10 = alpha\n",
        "\n",
        "# initialization of the vectors of losses and accuracies\n",
        "niter = 60\n",
        "loss1 = np.empty(niter)\n",
        "loss2 = np.empty(niter)\n",
        "loss3 = np.empty(niter)\n",
        "accuracy_train = np.empty(niter)\n",
        "accuracy_test = np.empty(niter)\n",
        "time1 = np.empty(niter)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_v_js(U1, U2, W, b, rho, gamma):\n",
        "    \"\"\"\n",
        "    The function updates the V_js parameters during the training phase\n",
        "    \n",
        "    :param U1: The U parameter on the same level of V that we are updating\n",
        "    :param U2: The U parameter which is in the next level of the V that we are updating\n",
        "    :param W: The W parameter which is in the next level of the V that we are updating\n",
        "    :param b: The b parameter which is in the next level of the V that we are updating\n",
        "    :param rho: The constant rho parameter which is in the next level of the V that we are updating\n",
        "    :param gamma: The constant gamma parameter which is in the next level of the V that we are updating\n",
        "    :return: The updated V\n",
        "    \"\"\"\n",
        "    _, d = W.size()\n",
        "    I = torch.eye(d, device=device)\n",
        "    U1 = nn.ReLU()(U1)\n",
        "    _, col_U2 = U2.size()\n",
        "    Vstar = torch.mm(torch.inverse(rho * (torch.mm(torch.t(W), W)) + gamma * I),\n",
        "                     rho * torch.mm(torch.t(W), U2 - b.repeat(1, col_U2)) + gamma * U1)\n",
        "    return Vstar\n",
        "\n",
        "\n",
        "def update_wb_js(U, V, W, b, alpha, rho):\n",
        "    \"\"\"\n",
        "    The function updates the W and b parameters during the training phase\n",
        "    \n",
        "    :param U: The U in the current level of W and b\n",
        "    :param V: The V in the previous level with respect to the W that we are updating\n",
        "    :param W: The current W that we have to update\n",
        "    :param b: The current b that we have to update\n",
        "    :param alpha: The alpha constant of the updates\n",
        "    :param rho: The rho constant of the updates\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    d, N = V.size()\n",
        "    I = torch.eye(d, device=device)\n",
        "    _, col_U = U.size()\n",
        "    Wstar = torch.mm(alpha * W + rho * torch.mm(U - b.repeat(1, col_U), torch.t(V)),\n",
        "                     torch.inverse(alpha * I + rho * (torch.mm(V, torch.t(V)))))\n",
        "    bstar = (alpha * b + rho * torch.sum(U - torch.mm(W, V), dim=1).reshape(b.size())) / (rho * N + alpha)\n",
        "    return Wstar, bstar\n",
        "\n",
        "\n",
        "def relu_prox(a, b, gamma, d, N):\n",
        "    \"\"\"\n",
        "    The function compute the solution to the relu proximal update problem\n",
        "    \n",
        "    :param a: the a in the closed formula of the linearized update\n",
        "    :param b: the b in the closed formula of the linearized update\n",
        "    :param gamma: The constant used in the update\n",
        "    :param d: the dimension of the current layer\n",
        "    :param N: The number of samples\n",
        "    :return: The obtained solution of the prox update\n",
        "    \"\"\"\n",
        "    val = torch.empty(d, N, device=device)\n",
        "    x = (a + gamma * b) / (1 + gamma)\n",
        "    y = torch.min(b, torch.zeros(d, N, device=device))\n",
        "    # torch.zeros(d,N, device=device)\n",
        "    val = torch.where(a + gamma * b < 0, y, torch.zeros(d, N, device=device))\n",
        "    val = torch.where(\n",
        "        ((a + gamma * b >= 0) & (b >= 0)) | ((a * (gamma - np.sqrt(gamma * (gamma + 1))) <= gamma * b) & (b < 0)), x,\n",
        "        val)\n",
        "    val = torch.where((-a <= gamma * b) & (gamma * b <= a * (gamma - np.sqrt(gamma * (gamma + 1)))), b, val)\n",
        "    return val"
      ],
      "metadata": {
        "id": "tpG7KN8JkT83"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "E_dJSsAAr_z1",
        "outputId": "0142a71b-3535-4100-b8f5-ba6f0ff3dde3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 / 60 \n",
            " - time: 2.462167739868164 - train_loss: 36282.0859375 - acc_train: 0.9688333333333333 - acc_test: 0.9565\n",
            "torch.Size([10, 60000])\n",
            "Epoch 53 / 60 \n",
            " - time: 2.5045430660247803 - train_loss: 35487.76953125 - acc_train: 0.96885 - acc_test: 0.9567\n",
            "torch.Size([10, 60000])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7c056b1798c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# update W2 and b2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_wb_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrho2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# update V1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-62ede74f11f5>\u001b[0m in \u001b[0;36mupdate_wb_js\u001b[0;34m(U, V, W, b, alpha, rho)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_U\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     Wstar = torch.mm(alpha * W + rho * torch.mm(U - b.repeat(1, col_U), torch.t(V)),\n\u001b[0;32m---> 38\u001b[0;31m                      torch.inverse(alpha * I + rho * (torch.mm(V, torch.t(V)))))\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mbstar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mWstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbstar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Iterations\n",
        "print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
        "for k in range(niter):\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # update V3\n",
        "    if (k == 1):\n",
        "      V3 = (y_one_hot + gamma3*U3 + alpha1*V3)/(1+ gamma3 + alpha1)\n",
        "    else:\n",
        "      print((torch.exp(V3)/torch.sum(torch.exp(V3),dim=0)).shape)\n",
        "      for i in range(200):\n",
        "        V3 = V3 - (torch.exp(V3)/torch.sum(torch.exp(V3),dim=0)-y_one_hot) * 0.01/(i+1)\n",
        "        \n",
        "    \n",
        "    # update U3 \n",
        "    U3 = (gamma3*V3 + rho3*(torch.mm(W3,V2) + b3.repeat(1,N)))/(gamma3 + rho3)\n",
        "\n",
        "    # update W3 and b3\n",
        "    W3, b3 = update_wb_js(U3,V2,W3,b3,alpha1,rho3)\n",
        "    \n",
        "    # update V2\n",
        "    V2 = update_v_js(U2,U3,W3,b3,rho3,gamma2)\n",
        "    \n",
        "    # update U2\n",
        "    U2 = relu_prox(V2,(rho2*torch.addmm(b2.repeat(1,N), W2, V1) + alpha2*U2)/(rho2 + alpha2),(rho2 + alpha2)/gamma2,d2,N)\n",
        "    \n",
        "    # update W2 and b2\n",
        "    W2, b2 = update_wb_js(U2,V1,W2,b2,alpha3,rho2)\n",
        "    \n",
        "    # update V1\n",
        "    V1 = update_v_js(U1,U2,W2,b2,rho2,gamma1)\n",
        "    \n",
        "    # update U1\n",
        "    U1 = relu_prox(V1,(rho1*torch.addmm(b1.repeat(1,N), W1, x_train) + alpha7*U1)/(rho1 + alpha7),(rho1 + alpha7)/gamma1,d1,N)\n",
        "    \n",
        "    # update W1 and b1\n",
        "    W1, b1 = update_wb_js(U1,x_train,W1,b1,alpha8,rho1)\n",
        "\n",
        "    a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
        "    a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
        "    pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
        "\n",
        "    a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
        "    a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
        "    pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
        "    \n",
        "    loss1[k] = gamma3/2*torch.pow(torch.dist(V3,y_one_hot,2),2).cpu().numpy()\n",
        "    loss2[k] = loss1[k] + rho1/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, x_train),U1,2),2).cpu().numpy() \\\n",
        "    +rho2/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
        "    +rho3/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy()\n",
        "    loss3[k] = torch.sum(-torch.log(torch.exp(V3)/torch.sum(torch.exp(V3),dim=0)) * y_one_hot)\n",
        "    \n",
        "    # compute training accuracy\n",
        "    correct_train = pred == y_train\n",
        "    accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
        "    \n",
        "    # compute validation accuracy\n",
        "    correct_test = pred_test == y_test\n",
        "    accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
        "    \n",
        "    # compute training time\n",
        "    stop = time.time()\n",
        "    duration = stop - start\n",
        "    time1[k] = duration\n",
        "    \n",
        "    # print results\n",
        "    print('Epoch', k + 1, '/', niter, '\\n', \n",
        "          '-', 'time:', time1[k], '-', 'train_loss:', loss3[k], \n",
        "          '-', 'acc_train:', accuracy_train[k], '-', 'acc_test:', accuracy_test[k])\n",
        "    \n",
        "print('The total time spent is:', np.sum(time1), 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrFu1jgT3kLz"
      },
      "source": [
        "# Training\n",
        "\n",
        "Note: Fix it so that it moves everything to device in the following function and that it does the label sample split here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFw-MbOat5p6"
      },
      "outputs": [],
      "source": [
        "## We plot the train losses\n",
        "\n",
        "plot_train_losses(loss1.shape[0], loss1, 'Coordinate_descent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gF9-R3-uB3c"
      },
      "outputs": [],
      "source": [
        "## We plot the test accuracy\n",
        "\n",
        "plot_test_accuracy(accuracy_test.shape[0], accuracy_test, 'Coordinate_descent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKYWNxdibHks"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Block_coordinate_descent.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}