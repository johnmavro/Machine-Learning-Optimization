{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf28e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\anaconda3\\envs\\introml\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Luca\\anaconda3\\envs\\introml\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Luca\\anaconda3\\envs\\introml\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from Frank_Wolfe.DFW import *\n",
    "from Frank_Wolfe.utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834e829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_stats = True\n",
    "save_figs = True\n",
    "load = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b0cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_logits, reference):\n",
    "    \"\"\"\n",
    "    Compute the ratio of correctly predicted labels\n",
    "    :param predicted_logits: float32 tensor of shape (batch size, num classes)\n",
    "                        The logits predicted by the model\n",
    "    :param reference: int64 tensor of shape (batch_size) with the class number\n",
    "                        Ground-truth labels\n",
    "    :return: accuracy: float\n",
    "    \"\"\"\n",
    "\n",
    "    labels = torch.argmax(predicted_logits, 1)\n",
    "    correct_predictions = labels.eq(reference)\n",
    "    return correct_predictions.sum().float() / correct_predictions.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385b8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we download and normalize the datasets\n",
    "\n",
    "ts = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0,), (1,))])\n",
    "mnist_trainset = datasets.MNIST('../data', train=True, download=True, transform=ts)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e023e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "# we import the dataloaders\n",
    "\n",
    "dataset_test = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data', train=False, download=True, transform=torchvision.transforms.ToTensor()), \n",
    "  batch_size=100,\n",
    "  shuffle=True\n",
    ")\n",
    "dataset_train = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data', train=True, download=True, transform=torchvision.transforms.ToTensor()),\n",
    "  batch_size=batch_size,\n",
    "  shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196b3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 1500\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e29b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture definition\n",
    "\n",
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    \n",
    "    # fully connected neural network with 2 hidden layers with 1500 neurons each. We use ReLU activation functions\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MultiLayerPerceptron,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_in = nn.Linear(self.input_size,self.hidden_size,bias=True) # fully connected input_layer\n",
    "        self.fc_hid_1 = nn.Linear(self.hidden_size,self.hidden_size,bias=True) # fully connected hidden_layer_1\n",
    "        self.fc_hid_2 = nn.Linear(self.hidden_size,self.hidden_size,bias=True) # fully connected hidden_layer_2\n",
    "        self.fc_out = nn.Linear(self.hidden_size,self.output_size,bias=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, self.input_size)\n",
    "        x = self.relu(self.fc_in(x))\n",
    "        x = self.relu(self.fc_hid_1(x))\n",
    "        x = self.relu(self.fc_hid_2(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7cd9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the model\n",
    "mlp = MultiLayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405bc61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = DFW(mlp.parameters(), eta=learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b503191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset_train, dataset_test, optimizer, criterion, epochs, scheduler=None, lr_decrease=True):\n",
    "    \"\"\"\n",
    "    The function is used to train the neural network\n",
    "    :param model: <class '__main__.MultiLayerPerceptron'>\n",
    "                    The model we wish to train\n",
    "    :param dataset_train: <class 'torch.utils.data.dataloader.DataLoader'>\n",
    "                    The train pytorch dataloader\n",
    "    :param dataset_test: <class 'torch.utils.data.dataloader.DataLoader'>\n",
    "                    The test pytorch dataloader\n",
    "    :param optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "                    The used pytorch optimizer\n",
    "    :param criterion: <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
    "                    The loss used during the training\n",
    "    :param epochs: int\n",
    "                    The number of epochs\n",
    "    :return: train losses, accuracies: lists of training losses and test accuracies respectively\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs): # loop over the dataset multiple times\n",
    "        epoch_loss = 0.0 \n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        n_steps = 0\n",
    "        for batch_x, batch_y in dataset_train:\n",
    "            n_steps = n_steps+1\n",
    "            # batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "\n",
    "            #Get output and evaluate with loss function\n",
    "            predictions = model(batch_x)\n",
    "            loss = criterion(predictions,batch_y)\n",
    "            running_loss += loss.item() * len(batch_y)\n",
    "    \n",
    "            #Initialize optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #Update the network\n",
    "            optimizer.step(lambda: float(loss), model, batch_x, batch_y)\n",
    "            \n",
    "        running_loss = running_loss / n_steps\n",
    "        train_losses.append(running_loss)\n",
    "        print(running_loss)\n",
    "        \n",
    "        #Test the quality on the test set\n",
    "        model.eval()\n",
    "        accuracies_test = []\n",
    "        \n",
    "        for batch_x, batch_y in dataset_test:\n",
    "            # batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            # Evaluate the network (forward pass)\n",
    "            prediction = model(batch_x)\n",
    "            accuracies_test.append(accuracy(prediction, batch_y))\n",
    "    \n",
    "        print(\"Epoch {} | Test accuracy: {:.5f}\".format(epoch, sum(accuracies_test).item()/len(accuracies_test)))\n",
    "        \n",
    "        accuracies.append(sum(accuracies_test).item()/len(accuracies_test))\n",
    "    return train_losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d9a0bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "2301.4618118604026\n",
      "Epoch 0 | Test accuracy: 0.13450\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "2301.265275478363\n",
      "Epoch 1 | Test accuracy: 0.13910\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n",
      "******* Solving iteration 1 of the proximal *********\n",
      "******* Solving iteration 2 of the proximal *********\n",
      "******* Solving iteration 0 of the proximal *********\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13684/1274791307.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#train using DFW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13684/2986470870.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataset_train, dataset_test, optimizer, criterion, epochs, scheduler, lr_decrease)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m#Update the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\introml\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\introml\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Luca\\OptML_course\\project\\Machine-Learning-Optimization\\Frank_Wolfe\\DFW.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, model, batch_x, batch_y)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0miters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\introml\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Luca\\OptML_course\\project\\Machine-Learning-Optimization\\Frank_Wolfe\\DFW.py\u001b[0m in \u001b[0;36m_line_search\u001b[1;34m(self, loss, w_dict, criterion, iters, model, batch_x, batch_y)\u001b[0m\n\u001b[0;32m    120\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                         \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mw_0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mw_s\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mw_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m                         \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mw_s\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mw_0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m  \u001b[1;31m# TODO: READD WO IN THE UPDATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdenom\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m                         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#train using DFW\n",
    "train_losses, accuracies_test = train_model(mlp, dataset_train, dataset_test, optimizer, cross_entropy, num_epochs)\n",
    "\n",
    "end = time.time()\n",
    "print('\\n')\n",
    "print('The total time spent is', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10784159",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(num_epochs), accuracies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dict = {'epochs': num_epochs, 'train_losses': train_losses, 'test_accuracies': accuracies_test}\n",
    "results.update({'SGD': current_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e085029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save everything onto file\n",
    "if save_stats: \n",
    "    output_folder = os.path.join(os.getcwd(), 'results')  # set the folder\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/stats_dict_DFW.pkl'\n",
    "    with open(fname, 'wb') as handle:\n",
    "        pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    output_folder = os.path.join(os.getcwd(), 'results')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    fname = output_folder + '/stats_dict_DFW.pkl'\n",
    "    with open(fname, 'rb') as handle:\n",
    "        stats_dict_DFW = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610892d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict_DFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12377cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_DFW = stats_dict_DFW['DFW']['train_losses']\n",
    "train_losses_SGD = stats_dict_DFW['SGD']['train_losses']\n",
    "test_accuracies_DFW = stats_dict_DFW['DFW']['test_accuracies']\n",
    "test_accuracies_SGD = stats_dict_DFW['SGD']['test_accuracies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_epochs = 200\n",
    "plt.semilogx(np.arange(num_epochs), train_losses_DFW, label=\"DFW\")\n",
    "plt.semilogx(np.arange(num_epochs), train_losses_SGD, label=\"SGD\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Training loss for SGD and Deep Frank-Wolfe\")\n",
    "plt.savefig(\"losses.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_epochs = 200\n",
    "plt.plot(np.arange(num_epochs), test_accuracies_DFW, label=\"DFW\")\n",
    "plt.plot(np.arange(num_epochs), test_accuracies_SGD, label=\"SGD\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Test accuracy for SGD and Deep Frank-Wolfe\")\n",
    "plt.savefig(\"accuracies.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610290e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
