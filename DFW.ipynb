{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puJO6BZlNmuf",
    "outputId": "d4db712c-4e8d-462d-864b-a49b2f02b4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/Machine-Learning-Optimization_working\n"
     ]
    }
   ],
   "source": [
    "#@title Mount Drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Machine-Learning-Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mC7BWlWnoFBa",
    "outputId": "2679231c-c61d-4b83-f908-1a09e8be2ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: barbar in c:\\users\\federico betti\\anaconda3\\envs\\cs439\\lib\\site-packages (0.2.1)\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "!pip install barbar\n",
    "\n",
    "#@title Import and utilities \n",
    "\n",
    "from Frank_Wolfe.utils.utils import *\n",
    "from Frank_Wolfe.DFW import *\n",
    "from Frank_Wolfe.architectures import *\n",
    "from Frank_Wolfe.MultiClassHingeLoss import *\n",
    "from barbar import Bar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jf6SJcqjoUSA",
    "outputId": "5e6e9eb7-6603-455a-d747-e7b2b6fc43cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR10-dataset\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07f3e8913864957a81405e2b1700589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# prepare train and test datasets \u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m trainData \u001b[38;5;241m=\u001b[39m \u001b[43mdatasetDict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasetDict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainTransformDict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m testData \u001b[38;5;241m=\u001b[39m datasetDict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasetDict\u001b[39m\u001b[38;5;124m'\u001b[39m](root\u001b[38;5;241m=\u001b[39mroot, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     28\u001b[0m                                         transform\u001b[38;5;241m=\u001b[39mtestTransformDict[dataset_name])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# move the model to GPU\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\site-packages\\torchvision\\datasets\\cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\site-packages\\torchvision\\datasets\\cifar.py:141\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\site-packages\\torchvision\\datasets\\utils.py:430\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 430\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\site-packages\\torchvision\\datasets\\utils.py:141\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[1;32m--> 141\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\site-packages\\torchvision\\datasets\\utils.py:35\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[1;34m(url, filename, chunk_size)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: response\u001b[38;5;241m.\u001b[39mread(chunk_size), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[0;32m     37\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\site-packages\\torchvision\\datasets\\utils.py:35\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[0;32m     37\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\http\\client.py:462\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 462\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\http\\client.py:506\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    501\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    503\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 506\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#@title Choose dataset name and architecture of the network \n",
    "\n",
    "# Select the dataset and the architecture\n",
    "\n",
    "dataset_name = 'CIFAR10' #@param ['CIFAR10', 'CIFAR100']\n",
    "model_type = 'WideResNet' #@param ['DenseNet', 'WideResNet', 'GoogLeNet']\n",
    "\n",
    "# load the model\n",
    "if model_type == 'GoogLeNet':\n",
    "    model = GoogleNet(num_class=10 if dataset_name == \"CIFAR10\" else 100)\n",
    "elif model_type == 'DenseNet':\n",
    "    model = torchvision.models.densenet121(pretrained=False)\n",
    "elif model_type == 'WideResNet':\n",
    "    model =  WideResNet(num_classes=10 if dataset_name == \"CIFAR10\" else 100)\n",
    "else:\n",
    "    raise ValueError(\"Please, select an available architecture\")\n",
    "\n",
    "# setting dataset attributes, dictionary useful to normalize the images\n",
    "datasetDict = setDatasetAttributes(dataset_name)\n",
    "# transform operation\n",
    "trainTransformDict, testTransformDict = setTrainAndTest(dataset_name) \n",
    "root = f\"{dataset_name}-dataset\"\n",
    "\n",
    "# prepare train and test datasets \n",
    "trainData = datasetDict['datasetDict'](root=root, train=True, download=True,\n",
    "                                            transform=trainTransformDict[dataset_name])\n",
    "testData = datasetDict['datasetDict'](root=root, train=False,\n",
    "                                        transform=testTransformDict[dataset_name])\n",
    "# move the model to GPU\n",
    "model = model.to(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "C6IgJdqGoWkV"
   },
   "outputs": [],
   "source": [
    "#@title Choose optimizer and parameters \n",
    "\n",
    "# Choice of the optimizer and the parameters.\n",
    "\n",
    "# The parameters used in our experiments can be found\n",
    "# both in the report and at the end of the notebook.\n",
    "\n",
    "optimizer_name = \"DFW multistep\" #@param  ['DFW', 'Adam', 'SGD with scheduler', 'DFW multistep']\n",
    "eta =   0.1 #@param {type:\"number\"}\n",
    "momentum = 0.9 #@param {type:\"number\"}\n",
    "lr = 0.001 #@param {type:\"number\"}\n",
    "beta_1 = 0.9 #@param {type:\"number\"}\n",
    "beta_2 = 0.999 #@param {type:\"number\"}\n",
    "initial_prox_steps = 2 #@param {type: \"number\"}\n",
    "\n",
    "if optimizer_name != \"DFW multistep\":\n",
    "    initial_prox_steps = 1\n",
    "\n",
    "# define the optimizer\n",
    "\n",
    "if optimizer_name == \"DFW\" or optimizer_name == 'DFW multistep':\n",
    "    optimizer = DFW(params=model.parameters(), eta=eta, momentum=momentum,\n",
    "                    prox_steps=initial_prox_steps)\n",
    "    \n",
    "    assert initial_prox_steps > 0\n",
    "    assert eta > 0\n",
    "    assert 0 <= momentum <= 1\n",
    "elif optimizer_name == \"SGD with scheduler\":\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=lr,\n",
    "                              momentum=momentum)\n",
    "    scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "    assert 0 <= momentum <= 1\n",
    "elif optimizer_name == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr, \n",
    "                               betas=(beta_1, beta_2))\n",
    "    \n",
    "if optimizer_name == \"DFW\" or optimizer_name == \"DFW multistep\":\n",
    "    # we consider a convex and piece-wise linear objective for DFW\n",
    "    loss_criterion = MultiClassHingeLoss().to(device=\"cuda:0\")\n",
    "    # smoothening of the loss function for many classes\n",
    "    smoothing = True\n",
    "else: \n",
    "    # cross entropy otherwise\n",
    "    loss_criterion = nn.CrossEntropyLoss().to(device=\"cuda:0\")\n",
    "    smoothing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cq-yV7BYplnM",
    "outputId": "5b507142-acc3-4124-c9bc-4fbf2ae077e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0/50\n",
      "Evaluation of train data:\n",
      "50000/50000: [===============================>] - ETA 0.7s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 0/50: Train Loss 1.1074069875717163 | Test Loss 1.097416378211975 | Train Acc 0.09998 | Test Acc 0.1002\n",
      "Time elapsed for the current epoch 116.83940601348877\n",
      "\n",
      "Epoch 1/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 1/50: Train Loss 1.2463369568252562 | Test Loss 1.0503244495391846 | Train Acc 0.13936 | Test Acc 0.1632\n",
      "Time elapsed for the current epoch 331.5416555404663\n",
      "\n",
      "Epoch 2/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 2/50: Train Loss 1.0777584143829346 | Test Loss 1.0660836534500122 | Train Acc 0.16654 | Test Acc 0.226\n",
      "Time elapsed for the current epoch 331.6231348514557\n",
      "\n",
      "Epoch 3/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 3/50: Train Loss 1.0655776642608643 | Test Loss 1.043072096824646 | Train Acc 0.18616 | Test Acc 0.2315\n",
      "Time elapsed for the current epoch 331.66676235198975\n",
      "\n",
      "Epoch 4/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 4/50: Train Loss 1.0524564706802368 | Test Loss 1.0486506763458252 | Train Acc 0.20848 | Test Acc 0.2673\n",
      "Time elapsed for the current epoch 331.6608805656433\n",
      "\n",
      "Epoch 5/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 5/50: Train Loss 1.0378539235305786 | Test Loss 1.0379442756652832 | Train Acc 0.24008 | Test Acc 0.1802\n",
      "Time elapsed for the current epoch 331.596143245697\n",
      "\n",
      "Epoch 6/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 6/50: Train Loss 1.0327531456756591 | Test Loss 1.0406832153320313 | Train Acc 0.25826 | Test Acc 0.2996\n",
      "Time elapsed for the current epoch 331.6459639072418\n",
      "\n",
      "Epoch 7/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 7/50: Train Loss 1.0232938889694214 | Test Loss 1.020273078918457 | Train Acc 0.28408 | Test Acc 0.316\n",
      "Time elapsed for the current epoch 331.6892635822296\n",
      "\n",
      "Epoch 8/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 8/50: Train Loss 1.0084881286239624 | Test Loss 1.066634535598755 | Train Acc 0.31362 | Test Acc 0.3056\n",
      "Time elapsed for the current epoch 332.0305120944977\n",
      "\n",
      "Epoch 9/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 9/50: Train Loss 0.9862664909744263 | Test Loss 1.1467449785232544 | Train Acc 0.34588 | Test Acc 0.2954\n",
      "Time elapsed for the current epoch 335.5701081752777\n",
      "\n",
      "Epoch 10/50\n",
      "Training:\n",
      "50000/50000: [===============================>] - ETA 0.9s\n",
      "Evaluation of test data:\n",
      "10000/10000: [===============================>] - ETA 0.3s\n",
      "\n",
      " Finished epoch 10/50: Train Loss 0.9610643991279602 | Test Loss 1.0010498298645019 | Train Acc 0.38212 | Test Acc 0.3913\n",
      "Time elapsed for the current epoch 332.8381645679474\n",
      "\n",
      "Epoch 11/50\n",
      "Training:\n",
      " 1920/50000: [=>..............................] - ETA 320.2s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-648f67b83860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moptimizer_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DFW\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moptimizer_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DFW multistep'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#@title Train the network  \n",
    "\n",
    "# we will append our results on these lists\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "epochs_times = []\n",
    "\n",
    "# parameters for the training phase\n",
    "nepochs = 50 #@param {type:\"integer\"}\n",
    "batch_size = 128  #@param {type:\"integer\"}\n",
    "verbose = 0 #@param [0, 1]\n",
    "\n",
    "# Loaders\n",
    "trainLoader = torch.utils.data.DataLoader(trainData, batch_size=batch_size, shuffle=True,\n",
    "                                      pin_memory=torch.cuda.is_available(), num_workers=2)\n",
    "testLoader = torch.utils.data.DataLoader(testData, batch_size=batch_size, shuffle=False,\n",
    "                                      pin_memory=torch.cuda.is_available(), num_workers=2)\n",
    "\n",
    "# initialize necessary metrics objects\n",
    "train_loss, train_accuracy = AverageMeter(), AverageMeter()\n",
    "test_loss, test_accuracy = AverageMeter(), AverageMeter()\n",
    "\n",
    "# function to reset metrics\n",
    "def reset_metrics():\n",
    "    train_loss.reset()\n",
    "    train_accuracy.reset()\n",
    "    test_loss.reset()\n",
    "    test_accuracy.reset()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(data=\"train\"):\n",
    "    if data == \"train\":\n",
    "        loader = trainLoader\n",
    "        mean_loss, mean_accuracy = train_loss, train_accuracy\n",
    "    elif data == \"test\":\n",
    "        loader = testLoader\n",
    "        mean_loss, mean_accuracy = test_loss, test_accuracy\n",
    "    \n",
    "    sys.stdout.write(f\"Evaluation of {data} data:\\n\")\n",
    "    \n",
    "    # iteration over the dataset\n",
    "    for x_input, y_target in Bar(loader):\n",
    "        x_input, y_target = x_input.to(device=\"cuda:0\"), y_target.to(device=\"cuda:0\") # we move to GPU\n",
    "        output = model.eval()(x_input)\n",
    "        loss = loss_criterion(output, y_target)\n",
    "        \n",
    "        # update metrics\n",
    "        mean_loss(loss.item(), len(y_target)) \n",
    "        mean_accuracy(Utilities.categorical_accuracy(y_true=y_target, output=output), len(y_target))\n",
    "\n",
    "    \n",
    "# Training\n",
    "for epoch in range(nepochs + 1):\n",
    "    \n",
    "    start = time.time() # start to time\n",
    "    reset_metrics() # reset the metrics from the previous epoch\n",
    "    sys.stdout.write(f\"\\n\\nEpoch {epoch}/{nepochs}\\n\")\n",
    "    \n",
    "    if epoch == 0:\n",
    "        # First pass through the network to evaluate the model once to get the metrics\n",
    "        evaluate_model(data='train')\n",
    "    else:\n",
    "        if epoch > int(0.2 * nepochs) and optimizer_name == \"DFW multistep\" and asymptotic_prox_steps_num >1:\n",
    "            \n",
    "            # if we already finished the first 20% of the epochs we continue with single steps\n",
    "            optimizer.prox_steps = 1\n",
    "            \n",
    "        sys.stdout.write(f\"Training:\\n\")\n",
    "        for x_input, y_target in Bar(trainLoader):\n",
    "            x_input, y_target = x_input.to(device=\"cuda:0\"), y_target.to(device=\"cuda:0\")\n",
    "            optimizer.zero_grad()  # Zero the gradient buffers\n",
    "            output = model.train()(x_input) # compute the output\n",
    "            if dataset_name == \"CIFAR100\" and smoothing:\n",
    "              # smoothing of the loss for DFW\n",
    "              with set_smoothing_enabled(True):\n",
    "                loss = loss_criterion(output, y_target) # compute the loss\n",
    "            else:\n",
    "                loss = loss_critertion(output, y_target) # without smoothing\n",
    "            loss.backward()  # Backpropagation\n",
    "            if optimizer_name == \"DFW\" or optimizer_name == 'DFW multistep':\n",
    "                optimizer.step(lambda: float(loss))\n",
    "            else:\n",
    "                optimizer.step() \n",
    "            train_loss(loss.item(), len(y_target))\n",
    "            train_accuracy(Utilities.categorical_accuracy(y_true=y_target, output=output), len(y_target))\n",
    "\n",
    "    if optimizer_name == \"SGD with scheduler\":\n",
    "        scheduler.step()\n",
    "\n",
    "    # evalutate the model on the test set    \n",
    "    evaluate_model(data='test')\n",
    "    sys.stdout.write(f\"\\n Finished epoch {epoch}/{nepochs}: Train Loss {train_loss.result()} | Test Loss {test_loss.result()} | Train Acc {train_accuracy.result()} | Test Acc {test_accuracy.result()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldLaA2by6VYV"
   },
   "source": [
    "# Parameters used in the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7F6Ai3G6bFd"
   },
   "source": [
    "In order to reproduce our results (i.e. the training trends shown in the report), the following set of parameters should be used.\\\n",
    "If not specified otherwise, the remaining parameters (e.g. the stability perturbation $\\epsilon$ for Adam and Adagrad) are set to their default values.\n",
    "\n",
    "\n",
    "$\\text{Deep Frank Wolfe (single step and multistep)}$:\n",
    "```python\n",
    "eta = 0.1  # proximal coefficient\n",
    "momentum = 0.9  # momentum parameter\n",
    "optimizer = DFW(model.parameters(), eta=eta, \n",
    "            momentum=momentum, prox_steps=2) # or prox_steps=1\n",
    "```\n",
    "\n",
    "$\\textbf{Stochastic Gradient Descent with scheduler}$:\n",
    "```python\n",
    "lr = 0.1  # learning rate\n",
    "momentum = 0.9  # momentum parameter\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=lr,\n",
    "                              momentum=momentum)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)  # define scheduler\n",
    "```\n",
    "\n",
    "$\\textbf{Adam}$:\n",
    "```python\n",
    "lr = 0.001 # learning rate\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr, \n",
    "                               betas=(beta_1, beta_2))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Federico Betti\\Documents\\GitHub\\Machine-Learning-Optimization_new\\Frank_Wolfe\\utils\\utils.py:163: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_losses = np.array([stats_dict_list[i][list_optimizers_tilda[i]]['train_losses']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (51,) and (39,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#@param ['CIFAR10', 'CIFAR100']\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGoogLeNet\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#@param ['DenseNet', 'WideResNet', 'GoogLeNet']\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplot_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Machine-Learning-Optimization_new\\Frank_Wolfe\\utils\\utils.py:176\u001b[0m, in \u001b[0;36mplot_stats\u001b[1;34m(dataset_name, model_type)\u001b[0m\n\u001b[0;32m    174\u001b[0m ax[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxx-large\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    175\u001b[0m ax[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSGD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDFW\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDFW multistep\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 176\u001b[0m \u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m ax[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx-large\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    178\u001b[0m ax[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxx-large\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS439\\lib\\site-packages\\matplotlib\\axes\\_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (51,) and (39,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 964.8x345.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = 'CIFAR100' #@param ['CIFAR10', 'CIFAR100']\n",
    "model_type = 'GoogLeNet' #@param ['DenseNet', 'WideResNet', 'GoogLeNet']\n",
    "plot_stats(dataset_name, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DFW_on_github (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
