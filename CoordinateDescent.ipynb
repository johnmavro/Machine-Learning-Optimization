{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoordinateDescent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KDbRlCKv4U8",
        "outputId": "08b1b601-fa72-4465-ed3f-eff7ce963e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 1.10.0+cu111\n",
            "Torchvision Version: 0.11.1+cu111\n",
            "GPU is available? True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"Torchvision Version:\", torchvision.__version__)\n",
        "print(\"GPU is available?\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "nYF1cnvPwthx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imported datasets\n",
        "For the testing and comparison of our algorithms we will use the following datasets:\n",
        "\n",
        "1. MNIST"
      ],
      "metadata": {
        "id": "WqvTMJAbw74Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0,), (1,))])\n",
        "mnist_trainset = datasets.MNIST('../data', train=True, download=True, transform=ts)\n",
        "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=ts)"
      ],
      "metadata": {
        "id": "icE91aqaw110"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train - test split\n",
        "\n",
        "Code taken from https://github.com/timlautk/BCD-for-DNNs-PyTorch/blob/master/bcd_dnn_mlp_mnist.ipynb"
      ],
      "metadata": {
        "id": "2PEt-flsyEKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train-set initialization\n",
        "x_d0 = mnist_trainset[0][0].size()[0]\n",
        "x_d1 = mnist_trainset[0][0].size()[1]\n",
        "x_d2 = mnist_trainset[0][0].size()[2]\n",
        "N = x_d3 = len(mnist_trainset)\n",
        "K = 10\n",
        "x_train = torch.empty((N,x_d0*x_d1*x_d2), device=device)\n",
        "y_train = torch.empty(N, dtype=torch.long)\n",
        "for i in range(N): \n",
        "     x_train[i,:] = torch.reshape(mnist_trainset[i][0], (1, x_d0*x_d1*x_d2))\n",
        "     y_train[i] = mnist_trainset[i][1]\n",
        "x_train = torch.t(x_train)\n",
        "#y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train, (N, 1)), 1)\n",
        "#y_one_hot = torch.t(y_one_hot).to(device=device)\n",
        "y_train = y_train.to(device=device)\n",
        "\n",
        "#test-set initialization\n",
        "N_test = x_d3_test = len(mnist_testset)\n",
        "x_test = torch.empty((N_test,x_d0*x_d1*x_d2), device=device)\n",
        "y_test = torch.empty(N_test, dtype=torch.long)\n",
        "for i in range(N_test): \n",
        "     x_test[i,:] = torch.reshape(mnist_testset[i][0], (1, x_d0*x_d1*x_d2))\n",
        "     y_test[i] = mnist_testset[i][1]\n",
        "x_test = torch.t(x_test)\n",
        "#y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test, (N_test, 1)), 1)\n",
        "#y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
        "y_test = y_test.to(device=device)"
      ],
      "metadata": {
        "id": "hVoD2jFeg-69"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1000\n",
        "\n",
        "dataset_test = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('../data', train=False, download=True, transform=torchvision.transforms.ToTensor()), \n",
        "  batch_size=100,\n",
        "  shuffle=True\n",
        ")\n",
        "dataset_train = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('../data', train=True, download=True, transform=torchvision.transforms.ToTensor()),\n",
        "  batch_size=batch_size,\n",
        "  shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "oVkAgTGRo1is"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Base architecture\n",
        "\n",
        "For the MultiLayerPerceptron we have the parameters **input_size** , **hidden_size**,**output_size** corresponding to the size of the input layer, the hidden layer and the output layer, respectively.\n",
        "\n",
        "The MLP only has 3 layers like https://github.com/timlautk/BCD-for-DNNs-PyTorch/blob/master/bcd_dnn_mlp_mnist.ipynb as a starting point.\n",
        "\n",
        "Also we use ReLU currently for the same reason."
      ],
      "metadata": {
        "id": "Me_6E9_Hxsxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 28*28\n",
        "hidden_size = 1500\n",
        "output_size = 10"
      ],
      "metadata": {
        "id": "hlRg4UWiezMt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLayerPerceptron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MultiLayerPerceptron,self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc_in = nn.Linear(self.input_size,self.hidden_size,bias=True) #fully connected input_layer\n",
        "    self.fc_hid_1 = nn.Linear(self.hidden_size,self.hidden_size,bias=True) #fully connected hidden_layer_1\n",
        "    self.fc_hid_2 = nn.Linear(self.hidden_size,self.hidden_size,bias=True) #dully connected hidden_layer_2\n",
        "    self.fc_out = nn.Linear(self.hidden_size,self.output_size,bias=True)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    batch_size = x.shape[0]\n",
        "    x = x.view(batch_size, self.input_size)\n",
        "    x = self.relu(self.fc_in(x))\n",
        "    x = self.relu(self.fc_hid_1(x))\n",
        "    x = self.relu(self.fc_hid_2(x))\n",
        "    x = self.fc_out(x)\n",
        "    return x    "
      ],
      "metadata": {
        "id": "GsefsOFZxsC3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the model\n",
        "mlp = MultiLayerPerceptron().to(device)"
      ],
      "metadata": {
        "id": "mtZG5-wMN8iM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optimizers & Loss functions Definitions\n",
        "\n",
        "1. SGD from pytorch \n",
        "2. CrossEntropyLoss function criterion"
      ],
      "metadata": {
        "id": "jCDiTSRJ5PHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "optimizer_SGD = optim.SGD(mlp.parameters(), lr=learning_rate, momentum=0.9)\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_Adam = optim.Adam(mlp.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "SeZXPzre4W6j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics\n",
        "\n",
        "1. Accuracy"
      ],
      "metadata": {
        "id": "GKi5hB9T00qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(predicted_logits, reference):\n",
        "    \"\"\"\n",
        "    Compute the ratio of correctly predicted labels\n",
        "    \n",
        "    @param predicted_logits: float32 tensor of shape (batch size, num classes)\n",
        "    @param reference: int64 tensor of shape (batch_size) with the class number\n",
        "    \"\"\"\n",
        "    labels = torch.argmax(predicted_logits, 1)\n",
        "    correct_predictions = labels.eq(reference)\n",
        "    return correct_predictions.sum().float() / correct_predictions.nelement()"
      ],
      "metadata": {
        "id": "1ee-my4X07jr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "Note: Fix it so that it moves everything to device in the following function and that it does the label sample split here"
      ],
      "metadata": {
        "id": "WrFu1jgT3kLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,dataset_train,dataset_test,optimizer,criterion,epochs):\n",
        "  for epoch in range(epochs): # loop over the dataset multiple times\n",
        "    epoch_loss = 0.0 \n",
        "    model.train()\n",
        "    iteration = 0\n",
        "    for batch_x,batch_y in dataset_train:\n",
        "      batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
        "\n",
        "      #Get output and evaluate with loss function\n",
        "      predictions = model(batch_x)\n",
        "      loss = criterion(predictions,batch_y)\n",
        "\n",
        "      #Initialize optimizer\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      #Update the network\n",
        "      optimizer.step()\n",
        "    \n",
        "    #Test the quality on the test set\n",
        "    model.eval()\n",
        "    accuracies_test = []\n",
        "    for batch_x, batch_y in dataset_test:\n",
        "      batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "      # Evaluate the network (forward pass)\n",
        "      prediction = model(batch_x)\n",
        "      accuracies_test.append(accuracy(prediction, batch_y))\n",
        "    \n",
        "    print(\"Epoch {} | Test accuracy: {:.5f}\".format(epoch, sum(accuracies_test).item()/len(accuracies_test)))"
      ],
      "metadata": {
        "id": "DUIrevt50dvk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "#train using sgd\n",
        "train_model(mlp,dataset_train,dataset_test,optimizer_SGD,cross_entropy,num_epochs)\n",
        "\n",
        "#train using adam optimizer\n",
        "train_model(mlp,dataset_train,dataset_test,optimizer_Adam,cross_entropy,num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_O44lBu4TC_",
        "outputId": "8b6e5b9c-009a-405e-8831-a0d3a576c5a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Test accuracy: 0.13470\n",
            "Epoch 1 | Test accuracy: 0.41750\n",
            "Epoch 2 | Test accuracy: 0.61320\n",
            "Epoch 3 | Test accuracy: 0.65760\n",
            "Epoch 4 | Test accuracy: 0.65420\n",
            "Epoch 5 | Test accuracy: 0.63990\n",
            "Epoch 6 | Test accuracy: 0.63290\n",
            "Epoch 7 | Test accuracy: 0.62820\n",
            "Epoch 8 | Test accuracy: 0.63090\n",
            "Epoch 9 | Test accuracy: 0.65230\n",
            "Epoch 0 | Test accuracy: 0.95710\n",
            "Epoch 1 | Test accuracy: 0.96970\n",
            "Epoch 2 | Test accuracy: 0.97330\n",
            "Epoch 3 | Test accuracy: 0.97450\n",
            "Epoch 4 | Test accuracy: 0.98050\n",
            "Epoch 5 | Test accuracy: 0.97940\n",
            "Epoch 6 | Test accuracy: 0.97980\n",
            "Epoch 7 | Test accuracy: 0.98110\n",
            "Epoch 8 | Test accuracy: 0.98260\n",
            "Epoch 9 | Test accuracy: 0.98260\n"
          ]
        }
      ]
    }
  ]
}