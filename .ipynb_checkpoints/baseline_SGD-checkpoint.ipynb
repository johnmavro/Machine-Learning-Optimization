{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-KDbRlCKv4U8",
    "outputId": "08b1b601-fa72-4465-ed3f-eff7ce963e3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\anaconda3\\envs\\introml\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Luca\\anaconda3\\envs\\introml\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Luca\\anaconda3\\envs\\introml\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.8.1\n",
      "Torchvision Version: 0.2.2\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from utilities import *\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nYF1cnvPwthx"
   },
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqvTMJAbw74Q"
   },
   "source": [
    "# Imported datasets\n",
    "For the testing and comparison of our algorithms we will use the following datasets:\n",
    "\n",
    "1. MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "icE91aqaw110"
   },
   "outputs": [],
   "source": [
    "ts = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0,), (1,))])\n",
    "mnist_trainset = datasets.MNIST('../data', train=True, download=True, transform=ts)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PEt-flsyEKM"
   },
   "source": [
    "# Train - test split\n",
    "\n",
    "Code taken from https://github.com/timlautk/BCD-for-DNNs-PyTorch/blob/master/bcd_dnn_mlp_mnist.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hVoD2jFeg-69"
   },
   "outputs": [],
   "source": [
    "#train-set initialization\n",
    "x_d0 = mnist_trainset[0][0].size()[0]\n",
    "x_d1 = mnist_trainset[0][0].size()[1]\n",
    "x_d2 = mnist_trainset[0][0].size()[2]\n",
    "N = x_d3 = len(mnist_trainset)\n",
    "K = 10\n",
    "x_train = torch.empty((N,x_d0*x_d1*x_d2), device=device)\n",
    "y_train = torch.empty(N, dtype=torch.long)\n",
    "for i in range(N): \n",
    "    x_train[i,:] = torch.reshape(mnist_trainset[i][0], (1, x_d0*x_d1*x_d2))\n",
    "    y_train[i] = mnist_trainset[i][1]\n",
    "x_train = torch.t(x_train)\n",
    "#y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train, (N, 1)), 1)\n",
    "#y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)\n",
    "\n",
    "#test-set initialization\n",
    "N_test = x_d3_test = len(mnist_testset)\n",
    "x_test = torch.empty((N_test,x_d0*x_d1*x_d2), device=device)\n",
    "y_test = torch.empty(N_test, dtype=torch.long)\n",
    "for i in range(N_test): \n",
    "    x_test[i,:] = torch.reshape(mnist_testset[i][0], (1, x_d0*x_d1*x_d2))\n",
    "    y_test[i] = mnist_testset[i][1]\n",
    "x_test = torch.t(x_test)\n",
    "#y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test, (N_test, 1)), 1)\n",
    "#y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oVkAgTGRo1is"
   },
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "dataset_test = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data', train=False, download=True, transform=torchvision.transforms.ToTensor()), \n",
    "  batch_size=100,\n",
    "  shuffle=True\n",
    ")\n",
    "dataset_train = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data', train=True, download=True, transform=torchvision.transforms.ToTensor()),\n",
    "  batch_size=batch_size,\n",
    "  shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me_6E9_Hxsxw"
   },
   "source": [
    "# Base architecture\n",
    "\n",
    "For the MultiLayerPerceptron we have the parameters **input_size** , **hidden_size**,**output_size** corresponding to the size of the input layer, the hidden layer and the output layer, respectively.\n",
    "\n",
    "The MLP only has 3 layers like https://github.com/timlautk/BCD-for-DNNs-PyTorch/blob/master/bcd_dnn_mlp_mnist.ipynb as a starting point.\n",
    "\n",
    "Also we use ReLU currently for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hlRg4UWiezMt"
   },
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 1500\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GsefsOFZxsC3"
   },
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerPerceptron,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_in = nn.Linear(self.input_size,self.hidden_size,bias=True) #fully connected input_layer\n",
    "        self.fc_hid_1 = nn.Linear(self.hidden_size,self.hidden_size,bias=True) #fully connected hidden_layer_1\n",
    "        self.fc_hid_2 = nn.Linear(self.hidden_size,self.hidden_size,bias=True) #dully connected hidden_layer_2\n",
    "        self.fc_out = nn.Linear(self.hidden_size,self.output_size,bias=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, self.input_size)\n",
    "        x = self.relu(self.fc_in(x))\n",
    "        x = self.relu(self.fc_hid_1(x))\n",
    "        x = self.relu(self.fc_hid_2(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mtZG5-wMN8iM"
   },
   "outputs": [],
   "source": [
    "#initialize the model\n",
    "mlp = MultiLayerPerceptron().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCDiTSRJ5PHH"
   },
   "source": [
    "# Optimizers & Loss functions Definitions\n",
    "\n",
    "1. SGD from pytorch \n",
    "2. CrossEntropyLoss function criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SeZXPzre4W6j"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer_SGD = optim.SGD(mlp.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer_Adam = optim.Adam(mlp.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKi5hB9T00qg"
   },
   "source": [
    "# Metrics\n",
    "\n",
    "1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1ee-my4X07jr"
   },
   "outputs": [],
   "source": [
    "def accuracy(predicted_logits, reference):\n",
    "    \"\"\"\n",
    "    Compute the ratio of correctly predicted labels\n",
    "    \n",
    "    @param predicted_logits: float32 tensor of shape (batch size, num classes)\n",
    "    @param reference: int64 tensor of shape (batch_size) with the class number\n",
    "    \"\"\"\n",
    "    labels = torch.argmax(predicted_logits, 1)\n",
    "    correct_predictions = labels.eq(reference)\n",
    "    return correct_predictions.sum().float() / correct_predictions.nelement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrFu1jgT3kLz"
   },
   "source": [
    "# Training\n",
    "\n",
    "Note: Fix it so that it moves everything to device in the following function and that it does the label sample split here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DUIrevt50dvk"
   },
   "outputs": [],
   "source": [
    "def train_model(model,dataset_train,dataset_test,optimizer,criterion,epochs):\n",
    "    train_losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs): # loop over the dataset multiple times\n",
    "        epoch_loss = 0.0 \n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        n_steps =0\n",
    "        for batch_x,batch_y in dataset_train:\n",
    "            n_steps = n_steps+1\n",
    "            batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "\n",
    "            #Get output and evaluate with loss function\n",
    "            predictions = model(batch_x)\n",
    "            loss = criterion(predictions,batch_y)\n",
    "            running_loss += loss.item() * len(batch_y)\n",
    "    \n",
    "            #Initialize optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #Update the network\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss = running_loss / n_steps\n",
    "        train_losses.append(running_loss)\n",
    "        \n",
    "        #Test the quality on the test set\n",
    "        model.eval()\n",
    "        accuracies_test = []\n",
    "        \n",
    "        for batch_x, batch_y in dataset_test:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            # Evaluate the network (forward pass)\n",
    "            prediction = model(batch_x)\n",
    "            accuracies_test.append(accuracy(prediction, batch_y))\n",
    "    \n",
    "        print(\"Epoch {} | Test accuracy: {:.5f}\".format(epoch, sum(accuracies_test).item()/len(accuracies_test)))\n",
    "        \n",
    "        accuracies.append(sum(accuracies_test).item()/len(accuracies_test))\n",
    "    return train_losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_O44lBu4TC_",
    "outputId": "8b6e5b9c-009a-405e-8831-a0d3a576c5a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Test accuracy: 0.11080\n",
      "Epoch 1 | Test accuracy: 0.23380\n",
      "Epoch 2 | Test accuracy: 0.40590\n",
      "Epoch 3 | Test accuracy: 0.53010\n",
      "Epoch 4 | Test accuracy: 0.59430\n",
      "Epoch 5 | Test accuracy: 0.61660\n",
      "Epoch 6 | Test accuracy: 0.62730\n",
      "Epoch 7 | Test accuracy: 0.64500\n",
      "Epoch 8 | Test accuracy: 0.65920\n",
      "Epoch 9 | Test accuracy: 0.68360\n",
      "Epoch 10 | Test accuracy: 0.70420\n",
      "Epoch 11 | Test accuracy: 0.72390\n",
      "Epoch 12 | Test accuracy: 0.74740\n",
      "Epoch 13 | Test accuracy: 0.76970\n",
      "Epoch 14 | Test accuracy: 0.78680\n",
      "Epoch 15 | Test accuracy: 0.80010\n",
      "Epoch 16 | Test accuracy: 0.80950\n",
      "Epoch 17 | Test accuracy: 0.82250\n",
      "Epoch 18 | Test accuracy: 0.82990\n",
      "Epoch 19 | Test accuracy: 0.83810\n",
      "Epoch 20 | Test accuracy: 0.84530\n",
      "Epoch 21 | Test accuracy: 0.85460\n",
      "Epoch 22 | Test accuracy: 0.85950\n",
      "Epoch 23 | Test accuracy: 0.86410\n",
      "Epoch 24 | Test accuracy: 0.86800\n",
      "Epoch 25 | Test accuracy: 0.87190\n",
      "Epoch 26 | Test accuracy: 0.87540\n",
      "Epoch 27 | Test accuracy: 0.87760\n",
      "Epoch 28 | Test accuracy: 0.88120\n",
      "Epoch 29 | Test accuracy: 0.88410\n",
      "Epoch 30 | Test accuracy: 0.88620\n",
      "Epoch 31 | Test accuracy: 0.88810\n",
      "Epoch 32 | Test accuracy: 0.88950\n",
      "Epoch 33 | Test accuracy: 0.89160\n",
      "Epoch 34 | Test accuracy: 0.89230\n",
      "Epoch 35 | Test accuracy: 0.89340\n",
      "Epoch 36 | Test accuracy: 0.89530\n",
      "Epoch 37 | Test accuracy: 0.89660\n",
      "Epoch 38 | Test accuracy: 0.89830\n",
      "Epoch 39 | Test accuracy: 0.89900\n",
      "Epoch 40 | Test accuracy: 0.90030\n",
      "Epoch 41 | Test accuracy: 0.90160\n",
      "Epoch 42 | Test accuracy: 0.90320\n",
      "Epoch 43 | Test accuracy: 0.90350\n",
      "Epoch 44 | Test accuracy: 0.90560\n",
      "Epoch 45 | Test accuracy: 0.90590\n",
      "Epoch 46 | Test accuracy: 0.90800\n",
      "Epoch 47 | Test accuracy: 0.90870\n",
      "Epoch 48 | Test accuracy: 0.90940\n",
      "Epoch 49 | Test accuracy: 0.91010\n",
      "\n",
      "\n",
      "The total time spent is 553.3663082122803\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#train using sgd\n",
    "train_losses_SGD, accuracies_test_SGD = train_model(mlp, dataset_train, dataset_test, optimizer_SGD, cross_entropy, num_epochs)\n",
    "\n",
    "end = time.time()\n",
    "print('\\n')\n",
    "print('The total time spent is', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4332/656955689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## We plot the train losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_train_losses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses_SGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SGD'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "## We plot the train losses\n",
    "\n",
    "plot_train_losses(num_epochs, train_losses_SGD, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We plot the test accuracy\n",
    "\n",
    "plot_test_accuracy(num_epochs, accuracies_test_SGD, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CoordinateDescent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
