{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eab8d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DFW import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32b87197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.11.0+cpu\n",
      "Torchvision Version: 0.12.0+cpu\n",
      "GPU is available? False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b82ccafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aec7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0,), (1,))])\n",
    "mnist_trainset = datasets.MNIST('../data', train=True, download=True, transform=ts)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8986fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d0 = mnist_trainset[0][0].size()[0]\n",
    "x_d1 = mnist_trainset[0][0].size()[1]\n",
    "x_d2 = mnist_trainset[0][0].size()[2]\n",
    "N = x_d3 = len(mnist_trainset)\n",
    "K = 10\n",
    "x_train = torch.empty((N,x_d0*x_d1*x_d2), device=device)\n",
    "y_train = torch.empty(N, dtype=torch.long)\n",
    "for i in range(N): \n",
    "    x_train[i,:] = torch.reshape(mnist_trainset[i][0], (1, x_d0*x_d1*x_d2))\n",
    "    y_train[i] = mnist_trainset[i][1]\n",
    "x_train = torch.t(x_train)\n",
    "y_train = y_train.to(device=device)\n",
    "\n",
    "#test-set initialization\n",
    "N_test = x_d3_test = len(mnist_testset)\n",
    "x_test = torch.empty((N_test,x_d0*x_d1*x_d2), device=device)\n",
    "y_test = torch.empty(N_test, dtype=torch.long)\n",
    "for i in range(N_test): \n",
    "    x_test[i,:] = torch.reshape(mnist_testset[i][0], (1, x_d0*x_d1*x_d2))\n",
    "    y_test[i] = mnist_testset[i][1]\n",
    "x_test = torch.t(x_test)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "715dbb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "dataset_test = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data', train=False, download=True, transform=torchvision.transforms.ToTensor()), \n",
    "  batch_size=100,\n",
    "  shuffle=True\n",
    ")\n",
    "dataset_train = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data', train=True, download=True, transform=torchvision.transforms.ToTensor()),\n",
    "  batch_size=batch_size,\n",
    "  shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaf5b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 1500\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8c16094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerPerceptron,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_in = nn.Linear(self.input_size,self.hidden_size,bias=True) #fully connected input_layer\n",
    "        self.fc_hid_1 = nn.Linear(self.hidden_size,self.hidden_size,bias=True) #fully connected hidden_layer_1\n",
    "        self.fc_hid_2 = nn.Linear(self.hidden_size,self.hidden_size,bias=True) #dully connected hidden_layer_2\n",
    "        self.fc_out = nn.Linear(self.hidden_size,self.output_size,bias=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, self.input_size)\n",
    "        x = self.relu(self.fc_in(x))\n",
    "        x = self.relu(self.fc_hid_1(x))\n",
    "        x = self.relu(self.fc_hid_2(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98ba0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the model\n",
    "mlp = MultiLayerPerceptron().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a0c20ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer_SGD = optim.SGD(mlp.parameters(), lr=learning_rate, momentum=0.9)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_Adam = optim.Adam(mlp.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd56fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_logits, reference):\n",
    "    \"\"\"\n",
    "    Compute the ratio of correctly predicted labels\n",
    "    \n",
    "    @param predicted_logits: float32 tensor of shape (batch size, num classes)\n",
    "    @param reference: int64 tensor of shape (batch_size) with the class number\n",
    "    \"\"\"\n",
    "    labels = torch.argmax(predicted_logits, 1)\n",
    "    correct_predictions = labels.eq(reference)\n",
    "    return correct_predictions.sum().float() / correct_predictions.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f70b71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,dataset_train,dataset_test,optimizer,criterion,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        # loop over the dataset multiple times\n",
    "        epoch_loss = 0.0 \n",
    "        model.train()\n",
    "        iteration = 0\n",
    "        closure = None\n",
    "        for batch_x,batch_y in dataset_train:\n",
    "            batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "\n",
    "            # Get output and evaluate with loss function\n",
    "            predictions = model(batch_x)\n",
    "            loss = criterion(predictions,batch_y)\n",
    "\n",
    "            # Initialize optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #Update the network\n",
    "            optimizer.step(lambda: float(loss))\n",
    "\n",
    "        # Test the quality on the test set\n",
    "        model.eval()\n",
    "        accuracies_test = []\n",
    "        for batch_x, batch_y in dataset_test:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            # Evaluate the network (forward pass)\n",
    "            prediction = model(batch_x)\n",
    "            accuracies_test.append(accuracy(prediction, batch_y))\n",
    "\n",
    "        print(\"Epoch {} | Test accuracy: {:.5f}\".format(epoch, sum(accuracies_test).item()/len(accuracies_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Frank Wolfe optimizer with learning rate of 0.1\n",
    "optimizer = DFW(mlp.parameters(), eta=0.1)\n",
    "num_epochs = 10\n",
    "\n",
    "# train using Frank-Wolfe optimizer\n",
    "train_model(mlp, dataset_train, dataset_test, optimizer, cross_entropy, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS439",
   "language": "python",
   "name": "cs439"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
