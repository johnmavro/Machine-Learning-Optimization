{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KDbRlCKv4U8",
        "outputId": "2d13f520-8e30-4d49-c348-eafdb1cf629c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 1.11.0+cu113\n",
            "Torchvision Version: 0.12.0+cu113\n",
            "GPU is available? True\n"
          ]
        }
      ],
      "source": [
        "#@title Import and Utilities\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "from utilities import *\n",
        "from Torch_architectures import *\n",
        "from Train_functions import *\n",
        "from CD_utilities import *\n",
        "from layers import *\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"Torchvision Version:\", torchvision.__version__)\n",
        "print(\"GPU is available?\", torch.cuda.is_available())\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqvTMJAbw74Q"
      },
      "source": [
        "# Imported datasets\n",
        "For the testing and comparison of our algorithms we will use the following datasets:\n",
        "\n",
        "1. MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PEt-flsyEKM"
      },
      "source": [
        "# Train - test split\n",
        "\n",
        "The Code for the Block Coordinate Descent was mostly based on https://github.com/timlautk/BCD-for-DNNs-PyTorch/blob/master/bcd_dnn_mlp_mnist.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oVkAgTGRo1is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101fc42f-41b2-41b4-d02a-025d84cec7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#@title Dataset & Optimizer Selection\n",
        "ts = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0,), (1,))])\n",
        "\n",
        "# change the flag to choose the dataset to work with\n",
        "dataset_flag = \"CIFAR10\" #@param ['MNIST','FMNIST','CIFAR10']\n",
        "batch_size = 256 #@param {type:\"integer\"}\n",
        "if dataset_flag =='MNIST':\n",
        "  trainset = datasets.MNIST('../data', train=True, download=True, transform=ts)\n",
        "  testset = datasets.MNIST(root='../data', train=False, download=True, transform=ts)\n",
        "  dataset_train = torch.utils.data.DataLoader(testset,batch_size = 128, shuffle = True)\n",
        "  dataset_test = torch.utils.data.DataLoader(trainset,batch_size = batch_size,shuffle = True)\n",
        "elif dataset_flag =='FMNIST':\n",
        "  trainset = datasets.FashionMNIST('../data', train=True, download=True, transform=ts)\n",
        "  testset = datasets.FashionMNIST(root='../data', train=False, download=True, transform=ts)\n",
        "  dataset_train = torch.utils.data.DataLoader(testset,batch_size = 128, shuffle = True)\n",
        "  dataset_test = torch.utils.data.DataLoader(trainset,batch_size = batch_size,shuffle = True)\n",
        "elif dataset_flag=='CIFAR10':\n",
        "  trainset = datasets.CIFAR10('../data', train=True, download=True, transform=ts)\n",
        "  testset = datasets.CIFAR10(root='../data', train=False, download=True, transform=ts)\n",
        "  dataset_train = torch.utils.data.DataLoader(testset,batch_size = 128, shuffle = True)\n",
        "  dataset_test = torch.utils.data.DataLoader(trainset,batch_size = batch_size,shuffle = True)\n",
        "\n",
        "x_train, y_train, x_test, y_test,y_train_one_hot, y_test_one_hot, I1, I2 = load_dataset(trainset, testset,10)\n",
        "\n",
        "# we move to device to use GPU\n",
        "\n",
        "x_train = x_train.to(device = device)\n",
        "x_test = x_test.to(device = device)\n",
        "y_train = y_train.to(device = device)\n",
        "y_test = y_test.to(device = device)\n",
        "y_train_one_hot = y_train_one_hot.to(device)\n",
        "y_test_one_hot = y_test_one_hot.to(device)\n",
        "input_size = x_train.shape[0]\n",
        "hidden_size = int(1.5*input_size)\n",
        "output_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9lX28NWho-N4"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "#@title Model Selection\n",
        "model_name = 'Multilayer-Perceptron' #@param ['Multilayer-Perceptron']\n",
        "optimizer_name = \"Coordinate-Descent\" #@param ['SGD','Adam','Coordinate-Descent','Coordinate-Descent+SGD','Coordinate-Descent+Adam']\n",
        "momentum = 0.9 #@param {type:\"number\"}\n",
        "lr = 0.001 #@param {type:\"number\"}\n",
        "weight_decay = 0.00 #@param {type:\"number\"}\n",
        "beta_1 = 0.9 #@param {type:\"number\"}\n",
        "beta_2 = 0.999 #@param {type:\"number\"}\n",
        "epochs = 50 #@param {type:\"integer\"}\n",
        "#the ratio of the epochs for coordinate descent for mixed classifiers\n",
        "ratio =  0.6#@param {type:\"number\"}\n",
        "use_entropy = True #@param {type:\"boolean\"}\n",
        "linear_extension = False #@param {type:\"boolean\"}\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "if(model_name =='Multilayer-Perceptron'):\n",
        "  model = MultiLayerPerceptron(input_size,hidden_size,output_size) \n",
        "\n",
        "\n",
        "if (optimizer_name == \"SGD\" or optimizer_name == \"Coordinate-Descent+SGD\"):\n",
        "  #print(\"Got in SGD\")\n",
        "  optimizer = torch.optim.SGD(params=model.parameters(), lr=lr,\n",
        "                              momentum=momentum, weight_decay=weight_decay)\n",
        "  assert lr > 0\n",
        "  assert 0 <= momentum <= 1\n",
        "elif (optimizer_name == \"Adam\" or optimizer_name == \"Coordinate-Descent+Adam\"):\n",
        "  #print(\"Got in Adam\")\n",
        "  optimizer = torch.optim.Adam(params=model.parameters(), lr=lr, \n",
        "                               betas=(beta_1, beta_2), weight_decay=weight_decay)\n",
        "if(optimizer_name != 'Coordinate-Descent'):\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCDiTSRJ5PHH"
      },
      "source": [
        "# Optimizers & Loss functions Definitions\n",
        "\n",
        "1. SGD from pytorch \n",
        "2. CrossEntropyLoss function criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrFu1jgT3kLz"
      },
      "source": [
        "# Training\n",
        "\n",
        "Note: Fix it so that it moves everything to device in the following function and that it does the label sample split here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_O44lBu4TC_",
        "outputId": "84d4b2d7-7eb2-4baf-f5fb-edea4cdad7be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training BCD\n",
            "Epoch 1 / 50 \n",
            " - time: 18.31203818321228 - sq_loss: 114895.984375 - tot_loss: 2202.223332252548 - loss_class: 22980.58203125 - acc: 0.1429 - val_acc: 0.1409\n",
            "Epoch 2 / 50 \n",
            " - time: 19.155765771865845 - sq_loss: 114172.953125 - tot_loss: 1429.0080787355082 - loss_class: 22839.056640625 - acc: 0.29094 - val_acc: 0.2848\n",
            "Epoch 3 / 50 \n",
            " - time: 19.191007375717163 - sq_loss: 113490.421875 - tot_loss: 1240.6976878490302 - loss_class: 22707.8359375 - acc: 0.38468 - val_acc: 0.376\n",
            "Epoch 4 / 50 \n",
            " - time: 18.98080015182495 - sq_loss: 112862.25 - tot_loss: 1068.905744433962 - loss_class: 22588.060546875 - acc: 0.42182 - val_acc: 0.4053\n",
            "Epoch 5 / 50 \n",
            " - time: 18.73792004585266 - sq_loss: 112278.7421875 - tot_loss: 913.109833765775 - loss_class: 22477.453125 - acc: 0.44308 - val_acc: 0.4259\n",
            "Epoch 6 / 50 \n",
            " - time: 19.125234365463257 - sq_loss: 111726.71875 - tot_loss: 773.0521360978485 - loss_class: 22372.943359375 - acc: 0.453 - val_acc: 0.4345\n",
            "Epoch 7 / 50 \n",
            " - time: 18.93863296508789 - sq_loss: 111204.15625 - tot_loss: 648.5044282048942 - loss_class: 22274.689453125 - acc: 0.4623 - val_acc: 0.4436\n",
            "Epoch 8 / 50 \n",
            " - time: 18.889573097229004 - sq_loss: 110682.890625 - tot_loss: 539.1784626051783 - loss_class: 22176.26953125 - acc: 0.46622 - val_acc: 0.4466\n",
            "Epoch 9 / 50 \n",
            " - time: 18.814770698547363 - sq_loss: 110192.2265625 - tot_loss: 444.90320372134454 - loss_class: 22084.7890625 - acc: 0.47348 - val_acc: 0.4538\n",
            "Epoch 10 / 50 \n",
            " - time: 19.076464891433716 - sq_loss: 109685.4609375 - tot_loss: 365.1623267441988 - loss_class: 21989.56640625 - acc: 0.4748 - val_acc: 0.4539\n",
            "Epoch 11 / 50 \n",
            " - time: 19.01809334754944 - sq_loss: 109214.6953125 - tot_loss: 299.70288251638414 - loss_class: 21902.77734375 - acc: 0.4799 - val_acc: 0.4586\n",
            "Epoch 12 / 50 \n",
            " - time: 18.976202726364136 - sq_loss: 108712.8203125 - tot_loss: 247.9811349570751 - loss_class: 21808.94921875 - acc: 0.48064 - val_acc: 0.4589\n",
            "Epoch 13 / 50 \n",
            " - time: 18.98598074913025 - sq_loss: 108246.046875 - tot_loss: 209.69601280987266 - loss_class: 21723.67578125 - acc: 0.4858 - val_acc: 0.4616\n",
            "Epoch 14 / 50 \n",
            " - time: 18.857019186019897 - sq_loss: 107759.109375 - tot_loss: 184.58906366229058 - loss_class: 21633.529296875 - acc: 0.48634 - val_acc: 0.4612\n",
            "Epoch 15 / 50 \n",
            " - time: 18.968127012252808 - sq_loss: 107292.8984375 - tot_loss: 172.28764149546623 - loss_class: 21548.95703125 - acc: 0.49112 - val_acc: 0.4638\n",
            "Epoch 16 / 50 \n",
            " - time: 19.006948232650757 - sq_loss: 106814.2734375 - tot_loss: 172.1826196551323 - loss_class: 21461.302734375 - acc: 0.49122 - val_acc: 0.4615\n",
            "Epoch 17 / 50 \n",
            " - time: 18.985831260681152 - sq_loss: 106351.46875 - tot_loss: 183.8803407430649 - loss_class: 21378.283203125 - acc: 0.4955 - val_acc: 0.4651\n",
            "Epoch 18 / 50 \n",
            " - time: 19.014628648757935 - sq_loss: 105882.046875 - tot_loss: 207.10575476884844 - loss_class: 21293.353515625 - acc: 0.49586 - val_acc: 0.4629\n",
            "Epoch 19 / 50 \n",
            " - time: 18.98835039138794 - sq_loss: 105411.15625 - tot_loss: 241.26672718524935 - loss_class: 21209.484375 - acc: 0.50028 - val_acc: 0.4669\n",
            "Epoch 20 / 50 \n",
            " - time: 18.978662252426147 - sq_loss: 104952.296875 - tot_loss: 286.07820801734925 - loss_class: 21127.759765625 - acc: 0.5005 - val_acc: 0.464\n",
            "Epoch 21 / 50 \n",
            " - time: 19.125407218933105 - sq_loss: 104479.4296875 - tot_loss: 341.13087905645375 - loss_class: 21044.072265625 - acc: 0.50474 - val_acc: 0.4697\n",
            "Epoch 22 / 50 \n",
            " - time: 19.130378484725952 - sq_loss: 104025.828125 - tot_loss: 405.81657354831697 - loss_class: 20964.71875 - acc: 0.50586 - val_acc: 0.467\n",
            "Epoch 23 / 50 \n",
            " - time: 19.12285327911377 - sq_loss: 103562.984375 - tot_loss: 479.9334268331528 - loss_class: 20884.0546875 - acc: 0.50898 - val_acc: 0.4716\n",
            "Epoch 24 / 50 \n",
            " - time: 18.995352268218994 - sq_loss: 103109.3359375 - tot_loss: 563.0520261526109 - loss_class: 20805.75 - acc: 0.51116 - val_acc: 0.4703\n",
            "Epoch 25 / 50 \n",
            " - time: 19.0304696559906 - sq_loss: 102637.546875 - tot_loss: 654.7300127506255 - loss_class: 20723.921875 - acc: 0.51346 - val_acc: 0.4729\n",
            "Epoch 26 / 50 \n",
            " - time: 18.98990488052368 - sq_loss: 102196.7265625 - tot_loss: 754.416565656662 - loss_class: 20649.638671875 - acc: 0.51616 - val_acc: 0.4718\n",
            "Epoch 27 / 50 \n",
            " - time: 19.011043310165405 - sq_loss: 101729.875 - tot_loss: 861.908930015564 - loss_class: 20570.068359375 - acc: 0.51838 - val_acc: 0.4728\n",
            "Epoch 28 / 50 \n",
            " - time: 18.926836013793945 - sq_loss: 101295.9296875 - tot_loss: 976.8983428955079 - loss_class: 20498.0390625 - acc: 0.521 - val_acc: 0.4717\n",
            "Epoch 29 / 50 \n",
            " - time: 18.96237587928772 - sq_loss: 100819.1875 - tot_loss: 1098.860368680954 - loss_class: 20417.16015625 - acc: 0.52242 - val_acc: 0.4741\n",
            "Epoch 30 / 50 \n",
            " - time: 18.930984497070312 - sq_loss: 100390.6953125 - tot_loss: 1227.3427771091463 - loss_class: 20347.697265625 - acc: 0.5251 - val_acc: 0.472\n",
            "Epoch 31 / 50 \n",
            " - time: 18.89985203742981 - sq_loss: 99914.234375 - tot_loss: 1362.2499510765076 - loss_class: 20268.03515625 - acc: 0.52604 - val_acc: 0.4749\n",
            "Epoch 32 / 50 \n",
            " - time: 18.851186752319336 - sq_loss: 99487.5625 - tot_loss: 1503.1257546901704 - loss_class: 20199.6875 - acc: 0.52922 - val_acc: 0.4746\n",
            "Epoch 33 / 50 \n",
            " - time: 19.09378957748413 - sq_loss: 99032.203125 - tot_loss: 1649.5237203121187 - loss_class: 20125.28515625 - acc: 0.53108 - val_acc: 0.4767\n",
            "Epoch 34 / 50 \n",
            " - time: 18.743222951889038 - sq_loss: 98607.0546875 - tot_loss: 1801.3183125495912 - loss_class: 20058.2109375 - acc: 0.5337 - val_acc: 0.4761\n",
            "Epoch 35 / 50 \n",
            " - time: 18.889461517333984 - sq_loss: 98143.4140625 - tot_loss: 1958.0667553901674 - loss_class: 19982.38671875 - acc: 0.53442 - val_acc: 0.4766\n",
            "Epoch 36 / 50 \n",
            " - time: 18.953765392303467 - sq_loss: 97743.765625 - tot_loss: 2119.6315214157103 - loss_class: 19922.212890625 - acc: 0.53794 - val_acc: 0.4769\n",
            "Epoch 37 / 50 \n",
            " - time: 18.77829933166504 - sq_loss: 97276.109375 - tot_loss: 2285.5755440711973 - loss_class: 19845.72265625 - acc: 0.53822 - val_acc: 0.4779\n",
            "Epoch 38 / 50 \n",
            " - time: 18.88356304168701 - sq_loss: 96869.65625 - tot_loss: 2455.7855143547063 - loss_class: 19784.76953125 - acc: 0.54144 - val_acc: 0.4771\n",
            "Epoch 39 / 50 \n",
            " - time: 19.068925380706787 - sq_loss: 96428.6875 - tot_loss: 2629.9922876358037 - loss_class: 19714.650390625 - acc: 0.54136 - val_acc: 0.4777\n",
            "Epoch 40 / 50 \n",
            " - time: 18.94329047203064 - sq_loss: 96029.1015625 - tot_loss: 2807.919409656525 - loss_class: 19656.044921875 - acc: 0.5446 - val_acc: 0.4781\n",
            "Epoch 41 / 50 \n",
            " - time: 18.83494257926941 - sq_loss: 95579.359375 - tot_loss: 2989.397684574127 - loss_class: 19584.4453125 - acc: 0.5457 - val_acc: 0.4764\n",
            "Epoch 42 / 50 \n",
            " - time: 18.92509388923645 - sq_loss: 95186.1328125 - tot_loss: 3174.2676223754884 - loss_class: 19527.69140625 - acc: 0.54808 - val_acc: 0.4776\n",
            "Epoch 43 / 50 \n",
            " - time: 18.93643021583557 - sq_loss: 94758.2578125 - tot_loss: 3362.297045516968 - loss_class: 19461.09375 - acc: 0.54792 - val_acc: 0.4764\n",
            "Epoch 44 / 50 \n",
            " - time: 18.861554861068726 - sq_loss: 94360.90625 - tot_loss: 3553.4047346115117 - loss_class: 19403.423828125 - acc: 0.5512 - val_acc: 0.4764\n",
            "Epoch 45 / 50 \n",
            " - time: 18.874929428100586 - sq_loss: 93970.171875 - tot_loss: 3747.351068496704 - loss_class: 19346.52734375 - acc: 0.55098 - val_acc: 0.4779\n",
            "Epoch 46 / 50 \n",
            " - time: 18.95632839202881 - sq_loss: 93577.3203125 - tot_loss: 3944.0065303802494 - loss_class: 19289.36328125 - acc: 0.55454 - val_acc: 0.4781\n",
            "Epoch 47 / 50 \n",
            " - time: 18.962515354156494 - sq_loss: 93171.859375 - tot_loss: 4143.324093055726 - loss_class: 19228.998046875 - acc: 0.55534 - val_acc: 0.4764\n",
            "Epoch 48 / 50 \n",
            " - time: 18.80366325378418 - sq_loss: 92796.2265625 - tot_loss: 4345.261654090881 - loss_class: 19175.607421875 - acc: 0.55672 - val_acc: 0.4777\n",
            "Epoch 49 / 50 \n",
            " - time: 18.94232201576233 - sq_loss: 92396.59375 - tot_loss: 4549.739155960084 - loss_class: 19116.88671875 - acc: 0.55738 - val_acc: 0.4768\n",
            "Epoch 50 / 50 \n",
            " - time: 18.843154191970825 - sq_loss: 92030.7734375 - tot_loss: 4756.583399009704 - loss_class: 19065.93359375 - acc: 0.55926 - val_acc: 0.4779\n",
            "The total time spent is: 947.2739474773407 s\n",
            "\n",
            "\n",
            "\n",
            "Early stopping accuracy: 0.4781\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "accuracy_train = []\n",
        "accuracy_test = []\n",
        "epochs_times = []\n",
        "start = time.time()\n",
        "if(optimizer_name == 'Coordinate-Descent' or optimizer_name == 'Coordinate-Descent+SGD' or optimizer_name== 'Coordinate-Descent+Adam'):\n",
        "  print('training BCD')\n",
        "  if(optimizer_name != 'Coordinate-Descent'):\n",
        "    total_epochs = epochs\n",
        "    epochs = int(total_epochs * ratio)\n",
        "  train_losses, test_losses , accuracy_train, accuracy_test,epochs_times,Ws,bs = execute_training([[\"Perceptron\",hidden_size,1],[\"Perceptron\",hidden_size,1]], input_size, hidden_size, output_size, x_train, x_test, y_train, y_test, y_train_one_hot, y_test_one_hot,\n",
        "                                         use_entropy, linear_extension, I1 = hidden_size,I2=1, niter = epochs, gamma = 0.1, alpha = 4)\n",
        "  #Train using BCD\n",
        "  if(optimizer_name != 'Coordinate-Descent'):\n",
        "    epochs = total_epochs-epochs\n",
        "if(optimizer_name != 'Coordinate-Descent'):\n",
        "  model = model.to(device)\n",
        "  #train using sgd or adam\n",
        "  if(optimizer_name == 'Coordinate-Descent+SGD' or optimizer_name == 'Coordinate-Descent+Adam'):\n",
        "    i=0\n",
        "    for param in model.parameters():\n",
        "      if i%2 == 0:\n",
        "        param.data = Ws[int(i/2)]\n",
        "        #temp_W.pop()\n",
        "      else:\n",
        "        param.data = torch.flatten(bs[int(i/2)])\n",
        "        #temp_b.pop()\n",
        "      i+=1\n",
        "  train_loss, test_loss, acc_train, acc_test, times = train_model(model, dataset_train, dataset_test, optimizer, cross_entropy, epochs,scheduler,optimizer_name)\n",
        "  train_losses = list(train_losses) + train_loss\n",
        "  test_losses = list(test_losses) + test_loss\n",
        "  accuracy_train = list(accuracy_train) + acc_train\n",
        "  accuracy_test = list(accuracy_test) + acc_test\n",
        "  epochs_times = list(epochs_times) + times\n",
        "elapsed_time = time.time() - start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "op31_mG1kcON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da709ea0-c25c-47b6-b254-53fb538ad500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coordinate-Descent\n"
          ]
        }
      ],
      "source": [
        "#Replace this with the same function as DFW\n",
        "results = {'epochs': epochs_times, 'train_losses': train_losses, \n",
        "           'train_acc': accuracy_train, 'test_losses': test_losses, \n",
        "           'test_acc': accuracy_test, 'elapsed_time': elapsed_time}\n",
        "stats_dict = {}\n",
        "stats_dict.update({optimizer_name: results})\n",
        "save_stats = True\n",
        "print(optimizer_name)\n",
        "# save everything onto file\n",
        "if save_stats: \n",
        "    output_folder = os.path.join(os.getcwd(), 'results')  # set the folder\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    fname = output_folder + '/stats_dict_' + model_name + '_' + optimizer_name + '-Entropy.pkl'\n",
        "    with open(fname, 'wb') as handle:\n",
        "        pickle.dump(stats_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "baseline_SGD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}